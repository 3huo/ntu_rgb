{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optical_flow as op_flow\n",
    "import ntu_rgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(im):\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.pkl found in current path. Use this file? [Y/n] \n"
     ]
    }
   ],
   "source": [
    "''' Get the dataset '''\n",
    "dataset = ntu_rgb.NTU()\n",
    "# dataset.load() # NOTE: only need to do once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make sure the metadata is correct:\n",
    "for m in dataset.metadata:\n",
    "    vid_num = m['video_index']\n",
    "    if vid_num % 1000 != 0:\n",
    "        continue\n",
    "    print(\"video:\", vid_num, \"loss:\", m['s_loss'])\n",
    "    rgb_im   = dataset.get_rgb_vid_images(vid_num)\n",
    "    depth_im = dataset.get_depth_images(vid_num)\n",
    "    d_2_r    = dataset.get_depth_2_rgb_map(vid_num)\n",
    "    new_rgb = np.zeros([depth_im.shape[1], depth_im.shape[2], 3])\n",
    "    for d_coord, rgb_coord in d_2_r.items():\n",
    "        new_rgb[d_coord[1], d_coord[0]] = rgb_im[0][int(rgb_coord[1]), int(rgb_coord[0])]\n",
    "    show(new_rgb.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_id = 0\n",
    "rgb_3D = dataset.get_rgb_3D_maps(vid_id)\n",
    "op_flow_2D = dataset.get_2D_optical_flow(vid_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "(16068,)\n",
      "(15414,)\n"
     ]
    }
   ],
   "source": [
    "print(len(rgb_3D))\n",
    "print(np.nonzero(rgb_3D[0])[0].shape)\n",
    "print(np.nonzero(rgb_3D[99])[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opflow_3D = dataset.get_3D_optical_flow(vid_id, rgb_3D, op_flow_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = len(opflow_3D)\n",
    "max_vecs = max([len(o) for o in opflow_3D.values()])\n",
    "\n",
    "opflow_ani = np.zeros([6,num_frames,max_vecs])\n",
    "for frame in opflow_3D:\n",
    "    for idx, vec in enumerate(opflow_3D[frame]):\n",
    "        opflow_ani[:,frame,idx] = vec\n",
    "\n",
    "opflow_ani[1,:,:] *= -1 # flip y axis\n",
    "opflow_ani[4,:,:] *= -1 # flip y vectors\n",
    "# opflow_ani[2,:,:] = np.power(opflow_ani[2,:,:], 3) # Increase spread of z values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume.pylab as p3\n",
    "print(\"shape of opflow data\", opflow_ani.shape)\n",
    "fig = p3.figure()\n",
    "# p3.zlim(2,8)\n",
    "q = p3.quiver(*opflow_ani[:,:,:], color=\"red\", size=3)\n",
    "p3.style.use(\"dark\") # looks better\n",
    "p3.animation_control(q, interval=100, add=True)\n",
    "p3.show()\n",
    "fig.animation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def set_view(figure, framenr, fraction):\n",
    "#     q.sequence_index = framenr\n",
    "#     p3.view(fraction*360 + 0.5, 0)\n",
    "# p3.movie('3D_opflow.mp4', set_view, frames=98*2, fps=20, gif_loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize point cloud\n",
    "vid_num = 6\n",
    "point_clouds = dataset.get_point_clouds(vid_num)\n",
    "from pyntcloud import PyntCloud\n",
    "df_pointcloud = pd.DataFrame(point_clouds[50,:,:], columns=['x','y','z'])\n",
    "cloud = PyntCloud(df_pointcloud)\n",
    "cloud.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize first set of images\n",
    "vid_num = 58\n",
    "m = dataset.metadata[vid_num]\n",
    "print(m['video_index'])\n",
    "rgb_im   = dataset.get_rgb_vid_images(vid_num)\n",
    "depth_im = dataset.get_depth_images(vid_num)\n",
    "for frame in range(rgb_im.shape[0]):\n",
    "    new_rgb = np.zeros([depth_im.shape[1], depth_im.shape[2], 3])\n",
    "    d_2_r = dataset.get_depth_2_rgb_map(vid_num, frame)\n",
    "    for d_coord, rgb_coord in d_2_r.items():\n",
    "        new_rgb[d_coord[1], d_coord[0]] = rgb_im[frame][int(rgb_coord[1]), int(rgb_coord[0])]\n",
    "    show(new_rgb.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optical flow\n",
    "vid_num = 58\n",
    "images = dataset.get_rgb_vid_images(vid_num, True)\n",
    "flow_maps = dataset.get_2D_flow_maps(vid_num)\n",
    "ani = op_flow.get_animation(images, flow_maps)\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_html5_video())\n",
    "# ani.save('2D_opflow.mp4', writer=\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Show epipolar line on an image\n",
    "'''\n",
    "\n",
    "def show_epipolar_line(skeleton_df, rgb_images, F):\n",
    "    frame = skeleton_df[skeleton_df['frame_index'] == 0]\n",
    "    im = rgb_images[0].copy()\n",
    "    \n",
    "    # Epipolar line (depth point -> color line)\n",
    "    epi = F @ np.array([frame['depth'].iloc[3][0], frame['depth'].iloc[3][1], 1.])\n",
    "\n",
    "    # Create epipolar line mask on RGB image\n",
    "    indices = np.ones([3, im.shape[0], im.shape[1]])\n",
    "    indices[:2,:,:] = np.indices([im.shape[0], im.shape[1]])\n",
    "    epi_mat = abs((indices[1] * epi[0]) + (indices[0] * epi[1]) + epi[2])\n",
    "    line_vals = epi_mat < 0.01\n",
    "\n",
    "    # Put red values on image \n",
    "    red_mat = np.zeros_like(im)\n",
    "    red_mat[1,:,:] = 255\n",
    "    im = np.where(np.stack([line_vals]*3,2), red_mat, im)\n",
    "\n",
    "    for x in range(-5,5):\n",
    "        for y in range(-5,5):\n",
    "            im[int(frame['color'].iloc[3][1]) + y, int(frame['color'].iloc[3][0]) + x] = np.array([0,255,0])\n",
    "\n",
    "    show(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RGB Intrinsic Parameters\n",
    "fx_rgb = 1.0820918205955327e+03\n",
    "fy_rgb = 1.0823759977994873e+03\n",
    "cx_rgb = 9.6692449993169430e+02\n",
    "cy_rgb = 5.3566594698237566e+02\n",
    "\n",
    "# Depth Intrinsic Parameters\n",
    "fx_d = 365.481\n",
    "fy_d = 365.481\n",
    "cx_d = 257.346\n",
    "cy_d = 210.347\n",
    "\n",
    "# Distortion parameters\n",
    "k1 = 0.0905474\n",
    "k2 = -0.26819\n",
    "k3 = 0.0950862\n",
    "p1 = 0.\n",
    "p2 = 0.\n",
    "\n",
    "# Rotation [depth-to-color] ; should this be transposed?\n",
    "R = -np.array([[9.9997086703565385e-01, -5.6336988734456616e-03, -5.1503899819367671e-03],\n",
    "               [5.6034256549301270e-03,  9.9996705123920560e-01, -5.8735046520488696e-03],\n",
    "               [5.1833098395106967e-03,  5.8444737120895603e-03,  9.9996948724755408e-01]])\n",
    "\n",
    "# 3D Translation (meters)\n",
    "t_x = 5.2236787502888557e-02\n",
    "t_y = -3.0543659328634320e-04\n",
    "t_z = -9.6233443531043941e-04\n",
    "\n",
    "# Matrix versions\n",
    "t_array = np.array([t_x, t_y, t_z])\n",
    "rgb_mat = np.array([[fx_rgb,     0., cx_rgb],\n",
    "                    [    0., fy_rgb, cy_rgb],\n",
    "                    [    0.,     0.,     1.]])\n",
    "d_mat   = np.array([[fx_d,   0., cx_d],\n",
    "                    [  0., fy_d, cy_d],\n",
    "                    [  0.,   0.,   1.]])\n",
    "dist_array = np.array([k1, k2, k3, p1, p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Old functions. todo: replace\n",
    "'''\n",
    "\n",
    "def find_scale_term(skeleton_df, R, T):\n",
    "    frame = skeleton_df[skeleton_df['frame_index'] == 0]\n",
    "    c_2D_gt = frame.iloc[3]['color']\n",
    "\n",
    "    # Convert depth to 3D:\n",
    "    u = frame['depth'].iloc[3][0]\n",
    "    v = frame['depth'].iloc[3][1]\n",
    "    z = frame['loc'].iloc[3][2]\n",
    "    d_3D = np.linalg.inv(d_mat) @ np.array([u, v, 1]) * z\n",
    "\n",
    "    # Convert 3D to rgb:\n",
    "    def loss_func(s):\n",
    "        rgb_3D = (R @ d_3D.reshape(1,-1).T) + T*s\n",
    "        c_2D = ((rgb_mat @ rgb_3D) / rgb_3D[2]).T[0][:2]\n",
    "        return np.linalg.norm(c_2D.T - c_2D_gt)\n",
    "    \n",
    "    opt_dict = scipy.optimize.minimize(loss_func, 0)\n",
    "    loss = opt_dict['fun']\n",
    "    scale = opt_dict['x'][0]\n",
    "    print(\"Scale: {} \\t (loss = {})\".format(scale, loss))\n",
    "    return scale\n",
    "\n",
    "def get_r_t(skeleton_df):\n",
    "    objectPoints = np.array([skeleton_df['loc']]).astype('float32')\n",
    "    rgb          = np.array([skeleton_df['color']]).astype('float32')\n",
    "    d            = np.array([skeleton_df['depth']]).astype('float32')\n",
    "\n",
    "    # Fundamental matrix\n",
    "    F, mask = cv2.findFundamentalMat(d, rgb)\n",
    "\n",
    "    # Essential matrix\n",
    "    E = rgb_mat.T @ F @ d_mat\n",
    "\n",
    "    # Decompose essential matrix\n",
    "    R1, R2, T = cv2.decomposeEssentialMat(E)\n",
    "\n",
    "    # Get the rotation matrix that looks more like the identity matrix\n",
    "    if abs(np.sum(R1 - np.identity(3))) < abs(np.sum(R2 - np.identity(3))):\n",
    "        R = R1\n",
    "    else:\n",
    "        R = R2\n",
    "\n",
    "    # print(\"Fundamental matrix:\\n\", F)\n",
    "    # print(\"Essential matrix:\\n\", E)\n",
    "    print(\"Rotation matrix:\\n\", R)\n",
    "    print(\"Translation (unit) d->rgb: \", T.T)\n",
    "    return R, T, F\n",
    "\n",
    "def rgb_2_depth(rgb, depth, R, T, s):\n",
    "    new_rgb = np.zeros([depth.shape[0], depth.shape[1], 3])\n",
    "    for y in range(depth.shape[0]):\n",
    "        for x in range(depth.shape[1]):            \n",
    "            ''' Set to black if nothing in depth '''\n",
    "            if depth[y,x] == 0:\n",
    "                new_rgb[y, x] = np.array([0,0,0])\n",
    "                continue\n",
    "            \n",
    "            ''' Convert to meters '''\n",
    "            z = depth[y,x] / 1000\n",
    "            \n",
    "            ''' Depth --> Camera coordinates '''\n",
    "            x_3D = (x - cx_d) * z / fx_d\n",
    "            y_3D = (y - cy_d) * z / fy_d\n",
    "            \n",
    "            ''' Apply rotation and translation '''\n",
    "            p0 = np.array([x_3D, y_3D, z])\n",
    "            p = (R @ p0.reshape(1,-1).T) + T*s\n",
    "\n",
    "            ''' Camera coordinates --> RGB '''\n",
    "            x_rgb = (p[0] * rgb_mat[0,0] / p[2]) + rgb_mat[0,2]\n",
    "            y_rgb = (p[1] * rgb_mat[1,1] / p[2]) + rgb_mat[1,2]\n",
    "            \n",
    "            if y_rgb >= 1080:\n",
    "                continue\n",
    "            if x_rgb >= 1920:\n",
    "                continue\n",
    "            new_rgb[y, x] = rgb[int(y_rgb), int(x_rgb)]\n",
    "    return new_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()\n",
    "# for vid in dataset.metadata[:200]:\n",
    "#     skeleton_df = dataset.get_skeleton_data(vid['video_index'])\n",
    "#     full_df = full_df.append(skeleton_df)\n",
    "\n",
    "\n",
    "first_vid = dataset.metadata[7000]['video_set']\n",
    "skeleton_dfs = []\n",
    "for idx, vid in enumerate(dataset.metadata):\n",
    "    if vid['video_set'][:2] == first_vid[:2]:\n",
    "        print(idx)\n",
    "        skeleton_dfs.append(dataset.get_skeleton_data(vid['video_index']))\n",
    "\n",
    "full_df = pd.concat(skeleton_dfs, ignore_index=True)\n",
    "R, T, F = get_r_t(full_df)\n",
    "\n",
    "videos_shown = []\n",
    "for index, m in full_df.iterrows():\n",
    "    vid_num = m['video_index']\n",
    "    if vid_num in videos_shown:\n",
    "        continue\n",
    "    else:\n",
    "        videos_shown.append(vid_num)\n",
    "    skeleton_df = dataset.get_skeleton_data(vid_num)\n",
    "    rgb_images  = dataset.get_rgb_vid_images(vid_num)\n",
    "    d_images    = dataset.get_depth_images(vid_num)\n",
    "    mins = find_scale_term(skeleton_df, R, T)\n",
    "    im = rgb_2_depth(rgb_images[0], d_images[0], R, T, mins)\n",
    "    show(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pyntcloud import PyntCloud\n",
    "# df_pointcloud = pd.DataFrame(point_clouds[0,:,:], columns=['x','y','z'])\n",
    "# cloud = PyntCloud(df_pointcloud)\n",
    "# cloud.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_images  = dataset.get_rgb_vid_images(0)\n",
    "flow_maps = dataset.get_2D_flow_maps(ir_images)\n",
    "ani = op_flow.get_animation(ir_images, flow_maps)\n",
    "from IPython.display import HTML\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ir_images  = dataset.get_ir_vid_images(0)\n",
    "# ir_images[:,:40,:] = 0\n",
    "# ir_images[:,-40:,:] = 0\n",
    "# ir_images[:,:,:40] = 0\n",
    "# ir_images[:,:,-40:] = 0\n",
    "# flow_maps = dataset.get_2D_flow_maps(ir_images)\n",
    "# ani = op_flow.get_animation(ir_images, flow_maps)\n",
    "# from IPython.display import HTML\n",
    "# HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save animation\n",
    "\n",
    "# ani.save('optical_flow_ir.mp4', writer=\"ffmpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for x in range(5):\n",
    "    vid_num = x*1234\n",
    "    rgb_images = dataset.get_rgb_vid_images(vid_num)\n",
    "    depth_images = dataset.get_depth_images(vid_num)\n",
    "    rgb_depth = rgb_2_d(rgb_images[0], depth_images[0])\n",
    "    show(rgb_depth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
